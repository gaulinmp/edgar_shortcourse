{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Words-in-the-filing\" data-toc-modified-id=\"Words-in-the-filing-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Words in the filing</a></span></li><li><span><a href=\"#Pages-in-the-filing\" data-toc-modified-id=\"Pages-in-the-filing\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Pages in the filing</a></span></li><li><span><a href=\"#Count-images\" data-toc-modified-id=\"Count-images-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Count images</a></span></li><li><span><a href=\"#Find-the-sections\" data-toc-modified-id=\"Find-the-sections-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Find the sections</a></span></li><li><span><a href=\"#Top-5-Salaries\" data-toc-modified-id=\"Top-5-Salaries-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Top 5 Salaries</a></span></li><li><span><a href=\"#Extracting-information\" data-toc-modified-id=\"Extracting-information-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Extracting information</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the filing at `cik=1652044`, `accession=0001308179-17-000170` ([link](https://www.sec.gov/Archives/edgar/data/1652044/000130817917000170/lgoog2017_def14a.htm)), read in the HTML and answer the following questions:\n",
    "\n",
    "\n",
    "\n",
    "  1. How many words are in the filing?\n",
    "  1. How many pages are in the filing?\n",
    "  1. How many images are included in the filing?\n",
    "  1. What are the different sections of the proxy statement? (hint: see the table of contents we found above).\n",
    "  1. What are the top 5 people (by salary) paid at Google?\n",
    "  1. *WITHOUT CODING*: Describe how you would go about extracting this information programatically.\n",
    "     1. What format is this information in?\n",
    "     1. Do you think it's repeatable for not-Google?\n",
    "     1. Would you use HTML or plain text to get this information?\n",
    "     1. Extra credit: Write out some [pseudo-code](https://www.vikingcodeschool.com/software-engineering-basics/what-is-pseudo-coding) for your approach, or just the steps in plain english."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-24T16:00:59.202018Z",
     "start_time": "2019-09-24T16:00:57.933610Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Import the filing\n",
    "import html2text\n",
    "from bs4 import BeautifulSoup\n",
    "from pyedgar import Filing\n",
    "\n",
    "# Load the filing\n",
    "filing = Filing(1652044, '0001308179-17-000170')\n",
    "\n",
    "# Get the HTML copy\n",
    "html = filing.documents[0]['full_text']\n",
    "\n",
    "# Get the beautifulsoup object of the HTML\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "# Get the plaintext version of the html\n",
    "h = html2text.HTML2Text()\n",
    "h.ignore_links = False\n",
    "h.ignore_tables = False\n",
    "plaintext = h.handle(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Words in the filing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using the word finder from last homework\n",
    "re_word_finder = re.compile(\n",
    "    r'\\b'                 # word-boundry, so match beginning or ends of words\n",
    "    r\"(?:[^\\W\\d_]|[-'])+\" # (?: is a non-capture group, just means we can use | for or.\n",
    "                          # ^\\W\\d_ means not (^) a non-word, or a digit or underscore\n",
    "    r'\\b'                 # ending word-boundry\n",
    "    , re.IGNORECASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Counting words in the plaintext\n",
    "num_words = len(re_word_finder.findall(plaintext))\n",
    "print(f\"Length of text: {len(plaintext):,d}\")\n",
    "print(f\"Number of words: {num_words:,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Counting words in the plaintext\n",
    "num_words = len(re_word_finder.findall(soup.get_text()))\n",
    "print(f\"Length of text: {len(soup.get_text()):,d}\")\n",
    "print(f\"Number of words: {num_words:,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's odd, I would think that plaintext (which leaves more formatting in) would be longer.\n",
    "Let's take a look at why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_sec = plaintext.index(\"Post-Employment and Change in Control Payments\")\n",
    "print(plaintext[ex_sec: ex_sec+2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_sec = soup.get_text().index(\"Post-Employment and Change in Control Payments\")\n",
    "print(soup.get_text()[ex_sec: ex_sec+2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a wordcount to see the top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pt = Counter(map(lambda x: x.lower(), re_word_finder.findall(plaintext)))\n",
    "num_pt.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_soup = Counter(map(lambda x: x.lower(), re_word_finder.findall(soup.get_text())))\n",
    "num_soup.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What words are in one and not the other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_pt_not_soup = set(num_pt.keys()) - set(num_soup.keys())\n",
    "in_pt_not_soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_soup_not_pt = set(num_soup.keys()) - set(num_pt.keys())\n",
    "in_soup_not_pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do those words alone explain the discrepancy? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 for w in re_word_finder.findall(plaintext) if w in in_pt_not_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(1 for w in re_word_finder.findall(soup.get_text()) if w in in_soup_not_pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_sum = 0\n",
    "for k in num_pt.keys():\n",
    "    dif = num_pt[k] - num_soup[k]\n",
    "    if dif != 0:\n",
    "        print(k, num_pt[k], num_soup[k])\n",
    "    dif_sum += dif\n",
    "print(dif_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dif_sum = 0\n",
    "for k in num_soup.keys():\n",
    "    dif = num_soup[k] - num_pt[k]\n",
    "    if dif != 0:\n",
    "        print(k, num_soup[k], num_pt[k])\n",
    "    dif_sum += dif\n",
    "print(dif_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I notice that alphabet seems to be pretty different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pt['alphabet'], num_soup['alphabet']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look through and see what matches from each text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [w for w in re_word_finder.findall(plaintext) if 'alphabet' in w.lower()]\n",
    "len(_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [w for w in re_word_finder.findall(soup.get_text()) if 'alphabet' in w.lower()]\n",
    "len(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look through, we see that plaintext gets lots of apostrophies, but soup.get_text() doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_txt = soup.get_text()\n",
    "for match in re_word_finder.finditer(_txt):\n",
    "    if 'alphabet' not in match.group(0).lower():\n",
    "        continue\n",
    "    print(_txt[match.start()-10:match.end()+10].replace('\\n', '\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for match in re_word_finder.finditer(plaintext):\n",
    "    if 'alphabet' not in match.group(0).lower():\n",
    "        continue\n",
    "    print(plaintext[match.start()-10:match.end()+10].replace('\\n', '\\t'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Using the word finder from last homework\n",
    "re_word_finder = re.compile(\n",
    "    r'\\b'                  # word-boundry, so match beginning or ends of words\n",
    "    r\"(?:[^\\W\\d_]|[-'’])+\" # Add ’, which is not just single quote, but single end quote\n",
    "    r'\\b'                  # ending word-boundry\n",
    "    , re.IGNORECASE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Counting words in the plaintext\n",
    "num_words = len(re_word_finder.findall(plaintext))\n",
    "print(f\"Length of text: {len(plaintext):,d}\")\n",
    "print(f\"Number of words: {num_words:,d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Counting words in the plaintext\n",
    "num_words = len(re_word_finder.findall(soup.get_text()))\n",
    "print(f\"Length of text: {len(soup.get_text()):,d}\")\n",
    "print(f\"Number of words: {num_words:,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Magnifique.\n",
    "\n",
    "See, regexes take lots of work, most of it iterative like this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pages in the filing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most EDGAR filings are broken up into pages. \n",
    "Maybe not all, but a lot.\n",
    "\n",
    "They look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll(style='font: 9pt Arial, Helvetica, Sans-Serif; margin: 0pt 0; text-align: right', limit=2)[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's just a break between pages, so we can look for those and count them.\n",
    "Looking at the page numbers will help us verify that we're doing it right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re.DOTALL is needed to let .* match newlines\n",
    "alpha_to_number = re.compile(r'^\\s*alphabet.*[^\\d]+\\d{1,3}\\s*$', re.IGNORECASE | re.DOTALL)\n",
    "\n",
    "pages = []\n",
    "for match in soup.findAll('p'):\n",
    "    txt = match.get_text()\n",
    "    if not alpha_to_number.search(txt):\n",
    "        continue\n",
    "    print(txt.strip().replace('\\n', ' '))\n",
    "    pages.append(txt.strip().split()[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of pages: {len(pages)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, we started at 4, so really there's 84 pages.\n",
    "But close enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_images = len(soup.findAll('img'))\n",
    "print(f\"Number of images: {num_images:,d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are these images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the sections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From `3_Scraping.ipynb`, You might remember we found the table of contents by looking for headers.\n",
    "Let' try that again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.findAll(text=re.compile('table.{0,20}contents', re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc = soup.findAll(text=re.compile('table.{0,20}contents', re.I))[0]\n",
    "toc.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toc.parent.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if toc.parent.parent.parent.name == 'body':\n",
    "    print(\"We've gone far enough.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's see if the TOC is the first table after that header we found above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(toc.parent.parent.findNext('table').prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we always look at our data when we develop algorithms, we instantly notice that the CD&A is missing.\n",
    "Why?\n",
    "\n",
    "Stupid pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = toc.parent.parent.findNext('table')\n",
    "html.findNext('table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ug, time to go look at the filing again.\n",
    "\n",
    "[Here's the link again](https://www.sec.gov/Archives/edgar/data/1652044/000130817917000170/lgoog2017_def14a.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table1 = toc.parent.parent.findNext('table')\n",
    "table2 = (table1.findNext(text=re.compile('compensation\\s+discussion\\s+and\\s+analysis', re.I))\n",
    "                .findParent('table'))\n",
    "HTML(table1.prettify() + table2.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we be sure that we're done?\n",
    "That's the hard part.\n",
    "\n",
    "You might think of looking for tables that just have words and one number, which sequentially increase.\n",
    "Or you could think of classifying each heading you can think of and then looking for all of them, grabbing the tables that enclose them.\n",
    "\n",
    "Hopefully you now see that parsing HTML is hard, and requires a lot of iteration on documents to see what is and isn't working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for tab in [table1, table2]:\n",
    "    for h1 in tab.findAll(attrs={'style':re.compile('font: 12pt Arial, Helvetica, Sans-Serif;')}):\n",
    "        text = h1.get_text().strip()\n",
    "        if len(text) <= 5:\n",
    "            # These are the page numbers\n",
    "            continue\n",
    "        text = re.sub('\\s+', ' ', text)\n",
    "        print(\"{})\".format(i), text)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Top 5 Salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I always start by finding it myself.\n",
    "For this, the inspector in chrome is absolutely invaluable.\n",
    "Learn it well, it will be your friend.\n",
    "\n",
    "[Documentation](https://developers.google.com/web/tools/chrome-devtools/inspect-styles/)\n",
    "\n",
    "I'm going to start by finding the \"Summary Compensation Table\", and taking the first table after that with salary in the header.\n",
    "Well that's my plan, we'll see if it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_comp = soup.findAll(text='Summary Compensation Table')\n",
    "sum_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've been here before, we probably want the second one.\n",
    "If we're in a table, that's the wrong one (TOC)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The carat means the start of the text, so not in the middle of a paragraph\n",
    "for sum_comp in soup.findAll(text=re.compile('^summary\\s+compensation\\s*table', re.I)):\n",
    "    print(sum_comp)\n",
    "    if sum_comp.findParent('table'):\n",
    "        print(\"We're in a table, move on.\")\n",
    "        continue\n",
    "    \n",
    "    print(\"We're not in a table. Go with this one.\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the next tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_table = (sum_comp.findNext('table', text=re.compile('salary', re.I))\n",
    "                     .findParent('table'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, I wonder why not.\n",
    "Let's try some things:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_comp.findNext('table', text=re.compile('salary', re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_comp.findNext('table', text=re.compile('salary', re.I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, nothing.\n",
    "Don't ask why I'd try this, but what about row instead of table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_comp.findNext('tr', text=re.compile('salary', re.I))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_comp.findNext('td', text=re.compile('salary', re.I))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay... odd.\n",
    "Well this works I guess."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_table = (sum_comp.findNext('td', text=re.compile('salary', re.I))\n",
    "                     .findParent('table'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(sum_table.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's the table we want.\n",
    "Now let's grab all the first columns with names in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sum_table.findAll('tr'):\n",
    "    cell = row.find('td') # the first cell\n",
    "    print(cell.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hmm, don't like all that noise.\n",
    "A quick look shows that the names are bolded.\n",
    "Let's just keep the bold then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sum_table.findAll('tr'):\n",
    "    # The named individuals are in bold.\n",
    "    bold_name_in_cell = row.find('td').find('b')\n",
    "    print(bold_name_in_cell.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh, some are none if 'b' isn't found. Ignore those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sum_table.findAll('tr'):\n",
    "    # The named individuals are in bold.\n",
    "    bold_name_in_cell = row.find('td').find('b')\n",
    "    if not bold_name_in_cell:\n",
    "        continue\n",
    "    print(bold_name_in_cell.get_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, we just want that first name in the cell, not the super-script (6):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sum_table.findAll('tr'):\n",
    "    # The named individuals are in bold.\n",
    "    bold_name_in_cell = row.find('td').find('b')\n",
    "    if not bold_name_in_cell:\n",
    "        continue\n",
    "    print(bold_name_in_cell.contents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we want to drop that first one.\n",
    "We know that these tables will have the hear associated with the salary in them, so let's check for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in sum_table.findAll('tr'):\n",
    "    # The named individuals are in bold.\n",
    "    if not row.find(text=re.compile('(?:19|20)\\d\\d')):\n",
    "        continue\n",
    "    bold_name_in_cell = row.find('td').find('b')\n",
    "    if not bold_name_in_cell:\n",
    "        continue\n",
    "    print(bold_name_in_cell.contents[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works, but we probably shouldn't be proud of it.\n",
    "Run it on any other document, and we'd get nothing.\n",
    "\n",
    "That figuring out a robust algorithm to handle all cases is where the real struggle lies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explanation of how I would think about approaching this**\n",
    "\n",
    "  1. Look at a few examples, try to find the similarities between them, as well as the variances.\n",
    "  1. Search across all Proxy statements for a simple regex of the name of the section or table title.\n",
    "  1. Based on how many proxies successfully match the regex, rework it until you get good coverage.\n",
    "  1. Start with a random document in a for loop, break out\n",
    "     1. e.g. `for row in df.iterrows(): filing=Filing(row.cik, row.accession);break`\n",
    "  1. Use BS to search for text around the table, then findNext('table') to get the table (if it's tabulated, which we hope it is).\n",
    "  1. Repeat this for a few more filings, test generalizability.\n",
    "  1. Probably fix many bugs, but do so iteratively, building up conditionals or a more robust regex as you go.\n",
    "  1. Extract all the tables possible\n",
    "  1. Extract data from tables:\n",
    "     1. Loop through tables and extract all column headers.\n",
    "     1. Determine similarities between them, group into whatever categories are reasonable.\n",
    "     1. Loop through rows in table, saving names, amounts by category into a list.\n",
    "     1. Load it all into a dataframe and save to disk."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "589.797px",
    "left": "1363.31px",
    "top": "135.797px",
    "width": "180.063px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
